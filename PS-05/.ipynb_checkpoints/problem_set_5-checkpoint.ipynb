{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center>Digital Image Processing - Problem Set 5</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Student Names: \n",
    "* Karolay Ardila Salazar\n",
    "* Julián Sibaja García\n",
    "* Andrés Simancas Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fall-Nature-Background-Pictures.jpg', 'Fig6.21(b).jpg', 'Woman.bmp', 'blown_ic.png', 'blurry_moon.png', 'bottles.png', 'building.jpg', 'cameraman.png', 'cameraman_new.png', 'check.png', 'chest.jpg', 'ckt_board_saltpep_prob_pt05.png', 'connected.jpg', 'contact_lens_original.png', 'crosses.png', 'darkPollen.jpg', 'dark_fountain.jpg', 'face.png', 'face.tif', 'fingerprint.jpg', 'flower.jpg', 'fruits.jpg', 'hiro.jpg', 'hubble-original.tif', 'hut.jpg', 'image_0001.jpg', 'image_0002.jpg', 'image_0003.jpg', 'image_0004.jpg', 'image_0005.jpg', 'image_0006.jpg', 'image_0007.jpg', 'image_0008.jpg', 'image_0009.jpg', 'image_0010.jpg', 'image_0011.jpg', 'image_0012.jpg', 'image_0013.jpg', 'image_0014.jpg', 'image_0015.jpg', 'image_0016.jpg', 'image_0017.jpg', 'image_0018.jpg', 'image_0019.jpg', 'image_0020.jpg', 'lena.jpg', 'lightPollen.jpg', 'lowContrastPollen.jpg', 'mms.jpg', 'moon.jpg', 'new_bottles.jpg', 'new_cameraman.png', 'new_chest.bmp', 'noisy_fingerprint.jpg', 'out.png', 'pollen.jpg', 'rectangle.png', 'rose.bmp', 'runway.jpg', 'shapes.PNG', 'skull.bmp', 'small_blobs.jpg', 'spheres.jpg', 'spine.jpg', 'squares.jpg', 'steve_blog.png', 'test_pattern_blurring_orig.png', 'three_bottles.jpg', 'translated_rectangle.png', 'weld_x-ray.jpg']\n"
     ]
    }
   ],
   "source": [
    "'''This is a definition script, so we do not have to rewrite code'''\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as mplt\n",
    "import random\n",
    "\n",
    "\n",
    "# set matplotlib to print inline (Jupyter)\n",
    "%matplotlib inline\n",
    "\n",
    "# path prefix\n",
    "pth = '../data/'\n",
    "\n",
    "# files to be used as samples\n",
    "# list *files* holds the names of the test images\n",
    "files = sorted(os.listdir(pth))\n",
    "print files\n",
    "\n",
    "# Usefull function\n",
    "def rg(img_path):\n",
    "    return cv2.imread(pth+img_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that describes <i>each</i> object in a binary image using the Hu statistical moments. The Hu moments are invariant to rotation, scale and translation. These moments can be defined for <i>each</i> region in a binary image. The OpenCV function to compute these moments is <tt>cv2.HuMoments</tt>. Write down the equations that compute the seven Hu moments for a region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that detects corners on an image using the Harris corner detection method. You can use the OpenCV built-in functions. Your function should output the $N$ detected corner locations in a $2 \\times N$ matrix. Visualize your results by plotting the corners on top of the input image.  Apply your function to the binary image <tt> shapes.png</tt> and to the grayscale image <tt>face.tif</tt>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A company that bottles a variety of industrial chemicals has heard\n",
    "of your success solving imaging problems and hires you to design an approach\n",
    "for detecting when bottles are not full. The bottles appear as shown below\n",
    "as they move along a conveyor line past an automatic\n",
    "filling and capping station. A bottle is considered imperfectly filled when the\n",
    "level of the liquid is below the midway point between the bottom of the neck and\n",
    "the shoulder of the bottle.The shoulder is defined as the region of the bottle\n",
    "where the sides and slanted portion of the bottle intersect. The bottles are\n",
    "moving, but the company has an imaging system equipped with an illumination\n",
    "flash front end that effectively stops motion, so you will be given images that\n",
    "look very close to the sample shown below.\n",
    "\n",
    "<img src=\"../data/files/bottles.png\" />\n",
    "\n",
    "Propose a solution for detecting\n",
    "bottles that are not filled properly. State clearly all assumptions that you\n",
    "make and that are likely to impact the solution you propose. Implement your\n",
    "solution and apply it to the images <tt>bottles.tif, new_bottles.jpg</tt> and <tt> three_bottles.jpg</tt>. Visualize the results\n",
    "of your algorithm by highlighting with false colors\n",
    "the regions that are detected as correctly\n",
    "filled bottles and the regions that are detected as not properly filled bottles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Suppose that you are observing objects in the night sky. Suppose that only ‘big’ objects are important to your observation. In this scenario, ‘small’ objects are considered noise. Write a python function that processes the image as follows:\n",
    "\n",
    "1. Use a 15x15 averaging filter to blur the image.\n",
    "\n",
    "2. Apply a threshold of 0.25 to binarize the resulting blurred image.\n",
    "\n",
    "3. Use the binary image to ‘mask’ the noise of the original image: simply perform an element-wise multiplication of the binary image and the original image.\n",
    "\n",
    "4. Use connected component analysis on the binary image to count the number of ‘big’ objects found.\n",
    "\n",
    "The function should take three inputs: an image matrix, the size of the averaging filter and threshold value. Make sure your function displays the intermediary results of each step outlined above.\n",
    "\n",
    "Apply your function to the input image ‘hubble-original.tif’. Try different values of smoothing kernel size and threshold value. Analyze the relationship between number of objects found and smoothing kernel size and threshold value. In particular, you might want to observe the result when using an averaging filter of size n=1 (i.e. no smoothing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that extracts local interest points and computes\n",
    "their descriptors using the SIFT transform. You can find implementations of\n",
    "the SIFT transform in OpenCV.\n",
    "\n",
    "\n",
    "Your function should return two matrices: A first matrix of size $3 \\times N$, where $N$ is the number of detected points in the image, and the 3 elements correspond to the $x$, $y$ locations and $s$ size of the detected points. A second matrix of size $128 \\times N$ that contains the SIFT descriptor of each interest point.\n",
    "\n",
    "Apply your function to all car images <tt>image_00XX.jpg</tt>.\n",
    "Store the results of each image in a separate data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDescriptors(img):\n",
    "    img = cv2.imread('home.jpg')\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp = sift.detect(gray,None)\n",
    "    img=cv2.drawKeypoints(gray,kp)\n",
    "    cv2.imwrite('sift_keypoints.jpg',img)\n",
    "    \n",
    "# 24 -44 ind of images of cars\n",
    "img_name = files[29]\n",
    "img = cv2.imread('../data/'+img_name,1) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
