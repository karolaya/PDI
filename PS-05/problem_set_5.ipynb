{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center>Digital Image Processing - Problem Set 5</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Student Names: \n",
    "* Karolay Ardila Salazar\n",
    "* Julián Sibaja García\n",
    "* Andrés Simancas Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fall-Nature-Background-Pictures.jpg', 'Fig6.21(b).jpg', 'Woman.bmp', 'blown_ic.png', 'blurry_moon.png', 'bottles.png', 'building.jpg', 'cameraman.png', 'cameraman_new.png', 'check.png', 'chest.jpg', 'ckt_board_saltpep_prob_pt05.png', 'connected.jpg', 'contact_lens_original.png', 'crosses.png', 'darkPollen.jpg', 'dark_fountain.jpg', 'face.png', 'face.tif', 'fingerprint.jpg', 'flower.jpg', 'fruits.jpg', 'hiro.jpg', 'hubble-original.tif', 'hut.jpg', 'image_0001.jpg', 'image_0002.jpg', 'image_0003.jpg', 'image_0004.jpg', 'image_0005.jpg', 'image_0006.jpg', 'image_0007.jpg', 'image_0008.jpg', 'image_0009.jpg', 'image_0010.jpg', 'image_0011.jpg', 'image_0012.jpg', 'image_0013.jpg', 'image_0014.jpg', 'image_0015.jpg', 'image_0016.jpg', 'image_0017.jpg', 'image_0018.jpg', 'image_0019.jpg', 'image_0020.jpg', 'lena.jpg', 'lightPollen.jpg', 'lowContrastPollen.jpg', 'mms.jpg', 'moon.jpg', 'new_bottles.jpg', 'new_cameraman.png', 'new_chest.bmp', 'noisy_fingerprint.jpg', 'out.png', 'pollen.jpg', 'rectangle.png', 'rose.bmp', 'runway.jpg', 'shapes.PNG', 'skull.bmp', 'small_blobs.jpg', 'spheres.jpg', 'spine.jpg', 'squares.jpg', 'steve_blog.png', 'test_pattern_blurring_orig.png', 'three_bottles.jpg', 'translated_rectangle.png', 'weld_x-ray.jpg']\n"
     ]
    }
   ],
   "source": [
    "'''This is a definition script, so we do not have to rewrite code'''\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as mplt\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "# set matplotlib to print inline (Jupyter)\n",
    "%matplotlib inline\n",
    "\n",
    "# path prefix\n",
    "pth = '../data/'\n",
    "\n",
    "# files to be used as samples\n",
    "# list *files* holds the names of the test images\n",
    "files = sorted(os.listdir(pth))\n",
    "print files\n",
    "\n",
    "# Usefull function\n",
    "def rg(img_path):\n",
    "    return cv2.imread(pth+img_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that describes <i>each</i> object in a binary image using the Hu statistical moments. The Hu moments are invariant to rotation, scale and translation. These moments can be defined for <i>each</i> region in a binary image. The OpenCV function to compute these moments is <tt>cv2.HuMoments</tt>. Write down the equations that compute the seven Hu moments for a region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that detects corners on an image using the Harris corner detection method. You can use the OpenCV built-in functions. Your function should output the $N$ detected corner locations in a $2 \\times N$ matrix. Visualize your results by plotting the corners on top of the input image.  Apply your function to the binary image <tt> shapes.png</tt> and to the grayscale image <tt>face.tif</tt>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A company that bottles a variety of industrial chemicals has heard\n",
    "of your success solving imaging problems and hires you to design an approach\n",
    "for detecting when bottles are not full. The bottles appear as shown below\n",
    "as they move along a conveyor line past an automatic\n",
    "filling and capping station. A bottle is considered imperfectly filled when the\n",
    "level of the liquid is below the midway point between the bottom of the neck and\n",
    "the shoulder of the bottle.The shoulder is defined as the region of the bottle\n",
    "where the sides and slanted portion of the bottle intersect. The bottles are\n",
    "moving, but the company has an imaging system equipped with an illumination\n",
    "flash front end that effectively stops motion, so you will be given images that\n",
    "look very close to the sample shown below.\n",
    "\n",
    "<img src=\"../data/files/bottles.png\" />\n",
    "\n",
    "Propose a solution for detecting\n",
    "bottles that are not filled properly. State clearly all assumptions that you\n",
    "make and that are likely to impact the solution you propose. Implement your\n",
    "solution and apply it to the images <tt>bottles.tif, new_bottles.jpg</tt> and <tt> three_bottles.jpg</tt>. Visualize the results\n",
    "of your algorithm by highlighting with false colors\n",
    "the regions that are detected as correctly\n",
    "filled bottles and the regions that are detected as not properly filled bottles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Suppose that you are observing objects in the night sky. Suppose that only ‘big’ objects are important to your observation. In this scenario, ‘small’ objects are considered noise. Write a python function that processes the image as follows:\n",
    "\n",
    "1. Use a 15x15 averaging filter to blur the image.\n",
    "\n",
    "2. Apply a threshold of 0.25 to binarize the resulting blurred image.\n",
    "\n",
    "3. Use the binary image to ‘mask’ the noise of the original image: simply perform an element-wise multiplication of the binary image and the original image.\n",
    "\n",
    "4. Use connected component analysis on the binary image to count the number of ‘big’ objects found.\n",
    "\n",
    "The function should take three inputs: an image matrix, the size of the averaging filter and threshold value. Make sure your function displays the intermediary results of each step outlined above.\n",
    "\n",
    "Apply your function to the input image ‘hubble-original.tif’. Try different values of smoothing kernel size and threshold value. Analyze the relationship between number of objects found and smoothing kernel size and threshold value. In particular, you might want to observe the result when using an averaging filter of size n=1 (i.e. no smoothing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write a function that extracts local interest points and computes\n",
    "their descriptors using the SIFT transform. You can find implementations of\n",
    "the SIFT transform in OpenCV.\n",
    "\n",
    "\n",
    "Your function should return two matrices: A first matrix of size $3 \\times N$, where $N$ is the number of detected points in the image, and the 3 elements correspond to the $x$, $y$ locations and $s$ size of the detected points. A second matrix of size $128 \\times N$ that contains the SIFT descriptor of each interest point.\n",
    "\n",
    "Apply your function to all car images <tt>image_00XX.jpg</tt>.\n",
    "Store the results of each image in a separate data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comentarios\n",
    "La Siguiente función hace uso de la implementación de la transformada de SIFT que tiene OpenCV. La función utilizada fue detectAndCompute. La función que se creó, recibe la array de una imagen en escala de grises y regresa los puntos (x,y) y la escala de la imagen en la que fueron encontrados como una matriz de numpy 3xN y también los respectivos descriptores de SIFT para cada punto en otra matriz. También se puede pasar como segundo parametro a la función un booleano que determina si se imprime o no la imagen con los puntos sobre ella, en el caso por defecto, que es False, no imprime nada. Los datos se guardan en archivos de texto en formato json.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points and SIFT descriptors for image 1 extracted\n",
      "Points and SIFT descriptors for image 2 extracted\n",
      "Points and SIFT descriptors for image 3 extracted\n",
      "Points and SIFT descriptors for image 4 extracted\n",
      "Points and SIFT descriptors for image 5 extracted\n",
      "Points and SIFT descriptors for image 6 extracted\n",
      "Points and SIFT descriptors for image 7 extracted\n",
      "Points and SIFT descriptors for image 8 extracted\n",
      "Points and SIFT descriptors for image 9 extracted\n",
      "Points and SIFT descriptors for image 10 extracted\n",
      "Points and SIFT descriptors for image 11 extracted\n",
      "Points and SIFT descriptors for image 12 extracted\n",
      "Points and SIFT descriptors for image 13 extracted\n",
      "Points and SIFT descriptors for image 14 extracted\n",
      "Points and SIFT descriptors for image 15 extracted\n",
      "Points and SIFT descriptors for image 16 extracted\n",
      "Points and SIFT descriptors for image 17 extracted\n",
      "Points and SIFT descriptors for image 18 extracted\n",
      "Points and SIFT descriptors for image 19 extracted\n",
      "Points and SIFT descriptors for image 20 extracted\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def getPointsAndDescriptors(img,show_img = False):\n",
    "    \n",
    "    # Getting Keypoint structure object and Descriptor Array\n",
    "    sift = cv2.SIFT()\n",
    "    kp, D = sift.detectAndCompute(img,None)\n",
    "    \n",
    "    # Getting the array of points (x,y,s)\n",
    "    points = np.zeros((3,len(kp)))\n",
    "    for i in range(len(kp)):\n",
    "        points[0][i] = kp[i].pt[0]\n",
    "        points[1][i] = kp[i].pt[1]\n",
    "        points[2][i] = kp[i].size\n",
    "        \n",
    "    if show_img == True:\n",
    "        img_s = cv2.drawKeypoints(img, kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        mplt.imshow(img_s), mplt.xticks([]), mplt.yticks([]), mplt.figure()\n",
    "    \n",
    "    return points, D\n",
    "    \n",
    "# 25 -45 ind of cars images\n",
    "for i in range(25,45):\n",
    "    img_name = files[i]\n",
    "    img = rg(img_name)\n",
    "    points, D = getPointsAndDescriptors(img)\n",
    "    f = open(\"data_image_\"+str(i-24)+\".json\",\"w\")\n",
    "    data = {\"points\":points.tolist(),\"Descriptors\": D.tolist()}\n",
    "    json.dump(data,f, sort_keys=True, indent=4)\n",
    "    f.close()\n",
    "    print \"Points and SIFT descriptors for image \"+str(i-24)+\" extracted\"\n",
    "    \n",
    "print \"Done!\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
